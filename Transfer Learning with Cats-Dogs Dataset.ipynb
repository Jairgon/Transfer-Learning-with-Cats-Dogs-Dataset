{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning Cats vs Dogs\n",
    "It recognizes an image and tells you if it is a cat or a dog.\n",
    "at the end you can upload your image and check it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os \n",
    "import zipfile\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ji= \"kagglecatsanddogs_3367a.zip\"\n",
    "\n",
    "zipa= zipfile.ZipFile(ji,\"r\")\n",
    "zipa.extractall(\"PetImages\")\n",
    "zipa.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of Cats  12501\n",
      " Number of Dogs  12501\n"
     ]
    }
   ],
   "source": [
    "print(\" Number of Cats \",len(os.listdir(\"petImages/cat\")))\n",
    "print(\" Number of Dogs \",len( os.listdir(\"petImages/dog\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folders.\n",
    "try:\n",
    "    os.mkdir(\"petImages/training\")\n",
    "    os.mkdir(\"petImages/testing\")\n",
    "    os.mkdir(\"petImages/training/cats\")\n",
    "    os.mkdir(\"petImages/testing/cats\")\n",
    "    os.mkdir(\"petImages/testing/dogs\")\n",
    "    os.mkdir(\"petImages/training/dogs\")\n",
    "    \n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 666.jpg is zero length\n",
      "The file 11702.jpg is zero length\n"
     ]
    }
   ],
   "source": [
    "# Split the images in training and testing folder.\n",
    "\n",
    "def split_function(source,training,testing,split_size):\n",
    "    files=[]\n",
    "    for w in os.listdir(source):\n",
    "        file= source+w\n",
    "        if os.path.getsize(file)>0:\n",
    "            files.append(w)\n",
    "        else:\n",
    "            print(f\"The file {w} is zero length\")\n",
    "            \n",
    "    train_size= int(len(files)*split_size)\n",
    "    test_size=int(len(files) -train_size)\n",
    "    \n",
    "    files_new= random.sample(files,len(files))\n",
    "    \n",
    "    train= files_new[:train_size]\n",
    "    test= files_new[train_size:]\n",
    "    \n",
    "    for m in train:\n",
    "        archivo= source+m\n",
    "        destination = training+m\n",
    "        copyfile(archivo,destination)\n",
    "        \n",
    "    for j in test:\n",
    "        archivo= source+j\n",
    "        destination= testing+j\n",
    "        copyfile(archivo,destination)\n",
    "        \n",
    "cat_source= \"petImages/cat/\"\n",
    "cat_training=\"petImages/training/cats/\"\n",
    "cat_testing= \"petImages/testing/cats/\"\n",
    "dog_source=\"petImages/dog/\"\n",
    "dog_training=\"petImages/training/dogs/\"\n",
    "dog_testing= \"petImages/testing/dogs/\"\n",
    "\n",
    "split_size=0.9\n",
    "        \n",
    "split_function(cat_source,cat_training,cat_testing,split_size)\n",
    "split_function(dog_source,dog_training,dog_testing,split_size)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Cats in training 12499\n",
      "Number of Dogs in training 12488\n",
      "Number of Dogs in testing 3401\n",
      "Number of Cats in testing 4291\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Number of Cats in training\",len(os.listdir(\"petImages/training/cats/\")))\n",
    "print(\"Number of Dogs in training\",len(os.listdir(\"petImages/training/dogs/\")))\n",
    "print(\"Number of Dogs in testing\",len(os.listdir(\"petImages/testing/dogs/\")))\n",
    "print(\"Number of Cats in testing\",len(os.listdir(\"petImages/testing/cats\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24985 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create the labels and change a little the images in training\n",
    "trian_dor=\"petImages/training/\"\n",
    "train_data= ImageDataGenerator(\n",
    "    rescale= 1/255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "    \n",
    "train_dir= train_data.flow_from_directory(\n",
    "    trian_dor,\n",
    "    target_size=(150,150),\n",
    "    batch_size=100,\n",
    "    class_mode=\"binary\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7690 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create the labels in testing\n",
    "\n",
    "validation_dor=\"petImages/testing/\"\n",
    "vali_data= ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "vali_dir= vali_data.flow_from_directory(\n",
    "    validation_dor,\n",
    "    target_size=(150,150),\n",
    "    batch_size=100,\n",
    "    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "link=\"inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "pre_trained_model= InceptionV3(input_shape=(150,150,3),\n",
    "    include_top=False,\n",
    "    weights=None)\n",
    "   \n",
    "# load pre-trained weights\n",
    "pre_trained_model.load_weights(link)\n",
    "\n",
    "# freeze the layers\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "last_layer= pre_trained_model.get_layer(\"mixed7\")\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "\n",
    "last_output=last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "print('last layer output shape: ', last_layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## definimos el modelo en un functional API\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 - 180s - loss: 0.6628 - acc: 0.8090 - val_loss: 0.1152 - val_acc: 0.9550\n",
      "Epoch 2/10\n",
      "20/20 - 192s - loss: 0.2048 - acc: 0.9110 - val_loss: 0.4663 - val_acc: 0.8400\n",
      "Epoch 3/10\n",
      "20/20 - 316s - loss: 0.2815 - acc: 0.8875 - val_loss: 0.1123 - val_acc: 0.9550\n",
      "Epoch 4/10\n",
      "20/20 - 251s - loss: 0.2123 - acc: 0.9060 - val_loss: 0.1148 - val_acc: 0.9600\n",
      "Epoch 5/10\n",
      "20/20 - 159s - loss: 0.2060 - acc: 0.9100 - val_loss: 0.1521 - val_acc: 0.9350\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carmona\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
      "  \"Possibly corrupt EXIF data.  \"\n",
      "C:\\Users\\Carmona\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
      "  \"Possibly corrupt EXIF data.  \"\n",
      "C:\\Users\\Carmona\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
      "  \"Possibly corrupt EXIF data.  \"\n",
      "C:\\Users\\Carmona\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \"Possibly corrupt EXIF data.  \"\n",
      "C:\\Users\\Carmona\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \"Possibly corrupt EXIF data.  \"\n",
      "C:\\Users\\Carmona\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \"Possibly corrupt EXIF data.  \"\n",
      "C:\\Users\\Carmona\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
      "  \"Possibly corrupt EXIF data.  \"\n",
      "C:\\Users\\Carmona\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:792: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 - 150s - loss: 0.1995 - acc: 0.9125 - val_loss: 0.0672 - val_acc: 0.9850\n",
      "Epoch 7/10\n",
      "20/20 - 134s - loss: 0.1786 - acc: 0.9255 - val_loss: 0.0331 - val_acc: 0.9850\n",
      "Epoch 8/10\n",
      "20/20 - 132s - loss: 0.1685 - acc: 0.9295 - val_loss: 0.0725 - val_acc: 0.9750\n",
      "Epoch 9/10\n",
      "20/20 - 146s - loss: 0.1816 - acc: 0.9255 - val_loss: 0.1017 - val_acc: 0.9600\n",
      "Epoch 10/10\n",
      "20/20 - 130s - loss: 0.1382 - acc: 0.9436 - val_loss: 0.0818 - val_acc: 0.9650\n"
     ]
    }
   ],
   "source": [
    "x= tf.keras.layers.Flatten()(last_output)\n",
    "x= tf.keras.layers.Dense(1024,activation=\"relu\")(x)\n",
    "x= tf.keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "model= Model(pre_trained_model.input,x)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=RMSprop(lr=0.0001),\n",
    "             metrics=[\"acc\"])\n",
    "history= model.fit(\n",
    "    train_dir,\n",
    "    validation_data=vali_dir,\n",
    "    validation_steps=2,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=20,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e5ee3b634a28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#put your image:\n",
    "\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "  path = '/content/' + fn\n",
    "  img = image.load_img(path, target_size=(150, 150))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "  image_tensor = np.vstack([x])\n",
    "  classes = model.predict(image_tensor)\n",
    "  print(classes)\n",
    "  print(classes[0])\n",
    "  if classes[0]>0.5:\n",
    "    print(fn + \" is a dog\")\n",
    "  else:\n",
    "    print(fn + \" is a cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
